{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5140550,"sourceType":"datasetVersion","datasetId":2534241}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nfrom PIL import Image\n\n# Auto select device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(\"Using device:\", device)\n\n# ---------------------------------------------------\n# Load metadata\n# ---------------------------------------------------\nwith open(\"/kaggle/input/cub2002011/CUB_200_2011/train_test_split.txt\") as f:\n    split = dict(line.strip().split() for line in f)\n\nwith open(\"/kaggle/input/cub2002011/CUB_200_2011/images.txt\") as f:\n    paths = dict(line.strip().split() for line in f)\n\nwith open(\"/kaggle/input/cub2002011/CUB_200_2011/image_class_labels.txt\") as f:\n    labels = dict(line.strip().split() for line in f)\n\n# ---------------------------------------------------\n# Select only FIRST 5 classes\n# ---------------------------------------------------\nselected_classes = set(list({int(v) for v in labels.values()})[:200])\n\nprint(\"Using classes:\", selected_classes)\n\ntrain_paths, train_labels = [], []\ntest_paths, test_labels = [], []\n\nbase = \"/kaggle/input/cub2002011/CUB_200_2011/images/\"\n\nfor img_id, rel in paths.items():\n    cls = int(labels[img_id])\n    if cls not in selected_classes:\n        continue\n\n    full = base + rel\n    if split[img_id] == \"1\":\n        train_paths.append(full)\n        train_labels.append(cls)\n    else:\n        test_paths.append(full)\n        test_labels.append(cls)\n\nprint(\"Train images:\", len(train_paths))\nprint(\"Test images :\", len(test_paths))\n\n# ---------------------------------------------------\n# Convert to DataFrames (path + class)\n# ---------------------------------------------------\ntrain_df = pd.DataFrame({\"path\": train_paths, \"class\": train_labels})\ntest_df  = pd.DataFrame({\"path\": test_paths , \"class\": test_labels})\n\n# ---------------------------------------------------\n# Per-class sample counts\n# ---------------------------------------------------\n\ntrain_count = train_df[\"class\"].value_counts().sort_index()\ntest_count  = test_df[\"class\"].value_counts().sort_index()\n\nprint(\"\\n===== TRAIN PER-CLASS COUNTS =====\")\nprint(train_count)\n\nprint(\"\\n===== TEST PER-CLASS COUNTS =====\")\nprint(test_count)\n\nprint(\"\\n===== SUMMARY =====\")\nprint(\"Train: classes =\", train_count.index.nunique(),\n      \"| min =\", train_count.min(),\n      \"| max =\", train_count.max(),\n      \"| avg =\", train_count.mean())\n\nprint(\"Test : classes =\", test_count.index.nunique(),\n      \"| min =\", test_count.min(),\n      \"| max =\", test_count.max(),\n      \"| avg =\", test_count.mean())\n\n# ---------------------------------------------------\n# Dataset class with transforms\n# ---------------------------------------------------\ntransform_train = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\ntransform_test = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(\n        mean=[0.485, 0.456, 0.406],\n        std=[0.229, 0.224, 0.225]\n    )\n])\n\nclass CUBDataset(Dataset):\n    def __init__(self, df, transform):\n        self.paths = df[\"path\"].values\n        self.labels = df[\"class\"].values\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n        img = Image.open(self.paths[idx]).convert(\"RGB\")\n        img = self.transform(img)\n        cls = self.labels[idx] - 1\n        return img, cls\n\n# ---------------------------------------------------\n# Dataloaders\n# ---------------------------------------------------\ntrain_dataset = CUBDataset(train_df, transform_train)\ntest_dataset = CUBDataset(test_df, transform_test)\n\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2)\ntest_loader  = DataLoader(test_dataset , batch_size=32, shuffle=False, num_workers=2)\n\nprint(\"Train loader batches:\", len(train_loader))\nprint(\"Test loader batches :\", len(test_loader))","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:43:55.128314Z","iopub.execute_input":"2025-11-14T06:43:55.128993Z","iopub.status.idle":"2025-11-14T06:44:03.314984Z","shell.execute_reply.started":"2025-11-14T06:43:55.128960Z","shell.execute_reply":"2025-11-14T06:44:03.314170Z"}},"outputs":[{"name":"stdout","text":"Using device: cuda\nUsing classes: {1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200}\nTrain images: 5994\nTest images : 5794\n\n===== TRAIN PER-CLASS COUNTS =====\nclass\n1      30\n2      30\n3      30\n4      30\n5      30\n       ..\n196    29\n197    30\n198    30\n199    30\n200    30\nName: count, Length: 200, dtype: int64\n\n===== TEST PER-CLASS COUNTS =====\nclass\n1      30\n2      30\n3      28\n4      30\n5      14\n       ..\n196    30\n197    30\n198    30\n199    30\n200    30\nName: count, Length: 200, dtype: int64\n\n===== SUMMARY =====\nTrain: classes = 200 | min = 29 | max = 30 | avg = 29.97\nTest : classes = 200 | min = 11 | max = 30 | avg = 28.97\nTrain loader batches: 188\nTest loader batches : 182\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# ===============================================================\n#   EVALUATION (AUTO-DETECT DVML OR NON-DVML)\n# ===============================================================\n\nimport torch\nimport torch.nn.functional as F\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import normalized_mutual_info_score, f1_score\nfrom sklearn.metrics import pairwise_distances\nimport numpy as np\n\n\n# -------------------------------------------------------\n# Extract embeddings (handles DVML + NON-DVML)\n# -------------------------------------------------------\ndef extract_embeddings(model, loader):\n    E, L = [], []\n    model.eval()\n\n    with torch.no_grad():\n        for imgs, lbls in loader:\n            imgs = imgs.to(device)\n\n            out = model(imgs, 0.0) if \"noise_scale\" in model.forward.__code__.co_varnames else model(imgs)\n\n            # --- DVML returns 6 outputs ---\n            if isinstance(out, tuple) and len(out) == 6:\n                z_i, z_v, mu, logvar, f, f_hat = out\n                z = z_i\n\n            # --- NON-DVML returns single embedding ---\n            else:\n                z = out\n\n            E.append(z.cpu())\n            L.append(lbls.cpu())\n\n    return torch.cat(E), torch.cat(L)\n\n\n# -------------------------------------------------------\n# Recall@K\n# -------------------------------------------------------\ndef recall_at_k(E, L, K=1):\n    E = F.normalize(E, dim=1)\n    sim = E @ E.t()\n\n    N = len(L)\n    sim[range(N), range(N)] = -1  # remove self-match\n\n    _, idx = sim.topk(K, dim=1)\n    return sum(L[i] in L[idx[i]] for i in range(N)) / N\n\n\n# -------------------------------------------------------\n# Clustering (NMI + F1)\n# -------------------------------------------------------\ndef clustering_metrics(E, L, num_classes):\n    km = KMeans(n_clusters=num_classes, n_init=10)\n    clusters = km.fit_predict(E)\n\n    nmi = normalized_mutual_info_score(L, clusters)\n    f1  = f1_score(L, clusters, average=\"macro\")\n\n    return nmi, f1\n\n\n# -------------------------------------------------------\n# Pairwise precision / recall\n# -------------------------------------------------------\ndef pairwise_precision_recall(E, L):\n    D = pairwise_distances(E)\n    y_true = (L[:, None] == L[None, :]).astype(int)\n\n    thr = np.median(D)\n    y_pred = (D < thr).astype(int)\n\n    TP = (y_pred * y_true).sum()\n    FP = (y_pred * (1 - y_true)).sum()\n    FN = ((1 - y_pred) * y_true).sum()\n\n    precision = TP / (TP + FP + 1e-9)\n    recall    = TP / (TP + FN + 1e-9)\n\n    return precision, recall\n\n\n# ===============================================================\n# RUN EVALUATION (WORKS FOR BOTH MODELS)\n# ===============================================================\nE, L = extract_embeddings(model, test_loader)\nnum_classes = len(torch.unique(L))\n\nprint(\"\\n============= METRIC LEARNING EVALUATION ==================\")\n\nfor k in [1, 2, 4, 8]:\n    print(f\"Recall@{k} =\", recall_at_k(E, L, k))\n\nnmi, f1 = clustering_metrics(E.numpy(), L.numpy(), num_classes)\nprint(\"\\nNMI =\", nmi)\nprint(\"F1  =\", f1)\n\nprec, rec = pairwise_precision_recall(E.numpy(), L.numpy())\nprint(\"\\nPairwise Precision =\", prec)\nprint(\"Pairwise Recall    =\", rec)\n\nprint(\"===========================================================\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:48:57.229463Z","iopub.execute_input":"2025-11-14T06:48:57.230117Z","iopub.status.idle":"2025-11-14T06:49:45.391981Z","shell.execute_reply.started":"2025-11-14T06:48:57.230087Z","shell.execute_reply":"2025-11-14T06:49:45.391038Z"}},"outputs":[{"name":"stdout","text":"\n============= METRIC LEARNING EVALUATION ==================\nRecall@1 = 0.21384190541939938\nRecall@2 = 0.3110113910942354\nRecall@4 = 0.4295823265447014\nRecall@8 = 0.5531584397652745\n\nNMI = 0.49230360033264897\nF1  = 0.007541941166252837\n\nPairwise Precision = 0.007867043919373791\nPairwise Recall    = 0.7788263049247964\n===========================================================\n\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torchvision import models\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import normalized_mutual_info_score, f1_score\nfrom sklearn.metrics import pairwise_distances\nimport numpy as np\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# -------------------------------------------------------\n# DVML MODEL (Z_I + Z_V) \n# -------------------------------------------------------\nclass DVML(nn.Module):\n    def __init__(self, embed_dim=512, var_dim=128, num_classes=200):\n        super().__init__()\n        goog = models.googlenet(weights=\"IMAGENET1K_V1\")\n\n        self.backbone = nn.Sequential(\n            goog.conv1, goog.maxpool1,\n            goog.conv2, goog.conv3, goog.maxpool2,\n            goog.inception3a, goog.inception3b, goog.maxpool3,\n            goog.inception4a, goog.inception4b, goog.inception4c,\n            goog.inception4d, goog.inception4e,\n            goog.maxpool4,\n            goog.inception5a, goog.inception5b,\n            goog.avgpool\n        )\n\n        self.fc_mu     = nn.Linear(1024, embed_dim)\n        self.fc_logvar = nn.Linear(1024, var_dim)\n\n        self.decoder = nn.Sequential(\n            nn.Linear(embed_dim, 512),\n            nn.ReLU(),\n            nn.Linear(512, 1024)\n        )\n\n        self.proxies = nn.Parameter(torch.randn(num_classes, embed_dim))\n\n    def encode(self, x):\n        f = self.backbone(x)\n        f = f.view(f.size(0), -1)\n        mu = self.fc_mu(f)\n        logvar = self.fc_logvar(f)\n        return mu, logvar, f\n\n    def sample(self, mu, logvar, noise_scale=1.0):\n        std = torch.exp(0.5 * logvar) * noise_scale\n        eps = torch.randn_like(std)\n        return mu + eps * std\n\n    def forward(self, x, noise_scale=1.0):\n        mu, logvar, f = self.encode(x)\n        z_i = mu\n        z_v = self.sample(mu, logvar, noise_scale)\n        f_hat = self.decoder(z_i)\n        return z_i, z_v, mu, logvar, f, f_hat\n\n\n# -------------------------------------------------------\n# Proxy NCA++\n# -------------------------------------------------------\nclass ProxyNCAPlusPlus(nn.Module):\n    def __init__(self, scale=8):\n        super().__init__()\n        self.scale = scale\n\n    def forward(self, z, labels, proxies):\n        z = F.normalize(z, dim=1)\n        p = F.normalize(proxies, dim=1)\n        sim = self.scale * (z @ p.t())\n        return F.cross_entropy(sim, labels)\n\n\ndef kl_loss(mu, logvar):\n    return -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n\n\ndef recon_loss(f, f_hat):\n    return F.mse_loss(f_hat, f)\n\n\n# -------------------------------------------------------\n# Model init\n# -------------------------------------------------------\nnum_classes = len(set([lbl for _, lbl in train_loader.dataset]))\nmodel = DVML(embed_dim=128, var_dim=128, num_classes=num_classes).to(device)\n\nif torch.cuda.device_count() > 1:\n    model = nn.DataParallel(model)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nproxynca = ProxyNCAPlusPlus(scale=8)\n\n\n# -------------------------------------------------------\n# TRAIN LOOP\n# -------------------------------------------------------\nfor epoch in range(4):\n    model.train()\n\n    kl_w = min(1.0, epoch / 20)\n    noise_scale = max(0.3, 1.0 - epoch / 10)\n\n    for imgs, labels in train_loader:\n        imgs = imgs.to(device)\n        labels = labels.to(device)\n\n        z_i, z_v, mu, logvar, f, f_hat = model(imgs, noise_scale)\n\n        proxies = model.module.proxies if isinstance(model, nn.DataParallel) else model.proxies\n        \n        loss_i = proxynca(z_i, labels, proxies)\n        loss_v = proxynca(z_v, labels, proxies)\n        loss_rec = recon_loss(f, f_hat)\n        loss_kl  = kl_loss(mu, logvar)\n\n        loss = loss_i + loss_v + loss_rec + kl_w * loss_kl\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n    print(\"Epoch\", epoch, \"Loss =\", loss.item())\n\n\n# -------------------------------------------------------\n# EXTRACT EMBEDDINGS (use Z_I for eval)\n# -------------------------------------------------------\ndef extract_embeddings(model, loader):\n    E, L = [], []\n    model.eval()\n    with torch.no_grad():\n        for imgs, lbls in loader:\n            imgs = imgs.to(device)\n            z_i, _, _, _, _, _ = model(imgs, noise_scale=0.0)\n            E.append(z_i.cpu())\n            L.append(lbls.cpu())\n    return torch.cat(E), torch.cat(L)\n\n\n# -------------------------------------------------------\n# Recall@K\n# -------------------------------------------------------\ndef recall_at_k(E, L, K=1):\n    E = F.normalize(E, dim=1)\n    S = E @ E.t()\n    N = len(L)\n    S[range(N), range(N)] = -1\n    _, idx = S.topk(K, dim=1)\n    c = 0\n    for i in range(N):\n        if L[i] in L[idx[i]]:\n            c += 1\n    return c / N\n\n\n# -------------------------------------------------------\n# NMI + F1\n# -------------------------------------------------------\ndef clustering_metrics(E, L, num_classes):\n    km = KMeans(n_clusters=num_classes, n_init=10)\n    C = km.fit_predict(E)\n    nmi = normalized_mutual_info_score(L, C)\n    f1 = f1_score(L, C, average=\"macro\")\n    return nmi, f1\n\n\n# -------------------------------------------------------\n# Pairwise precision / recall\n# -------------------------------------------------------\ndef pairwise_precision_recall(E, L):\n    D = pairwise_distances(E)\n    y_true = (L[:, None] == L[None, :]).astype(int)\n    thr = np.median(D)\n    y_pred = (D < thr).astype(int)\n\n    TP = (y_pred * y_true).sum()\n    FP = (y_pred * (1 - y_true)).sum()\n    FN = ((1 - y_pred) * y_true).sum()\n\n    precision = TP / (TP + FP + 1e-9)\n    recall    = TP / (TP + FN + 1e-9)\n    return precision, recall\n\n\n# -------------------------------------------------------\n# FULL EVALUATION\n# -------------------------------------------------------\nE, L = extract_embeddings(model, test_loader)\nnum_classes = len(torch.unique(L))\n\nprint(\"\\n================ EVALUATION ================\")\n\nfor k in [1,2,4,8]:\n    print(f\"Recall@{k} =\", recall_at_k(E, L, k))\n\nnmi, f1 = clustering_metrics(E.numpy(), L.numpy(), num_classes)\nprint(\"\\nNMI =\", nmi)\nprint(\"F1  =\", f1)\n\nprec, rec = pairwise_precision_recall(E.numpy(), L.numpy())\nprint(\"\\nPairwise Precision =\", prec)\nprint(\"Pairwise Recall    =\", rec)\n\nprint(\"============================================\\n\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-14T06:50:10.531492Z","iopub.execute_input":"2025-11-14T06:50:10.531832Z","iopub.status.idle":"2025-11-14T06:53:40.266548Z","shell.execute_reply.started":"2025-11-14T06:50:10.531806Z","shell.execute_reply":"2025-11-14T06:53:40.265748Z"}},"outputs":[{"name":"stdout","text":"Epoch 0 Loss = 9.597193717956543\nEpoch 1 Loss = 7.906866550445557\nEpoch 2 Loss = 5.977601051330566\nEpoch 3 Loss = 5.503684997558594\n\n================ EVALUATION ================\nRecall@1 = 0.5735243355195029\nRecall@2 = 0.6805315843976527\nRecall@4 = 0.7713151536071798\nRecall@8 = 0.8455298584742837\n\nNMI = 0.7246531908059644\nF1  = 0.0009588953567743827\n\nPairwise Precision = 0.009907411357092184\nPairwise Recall    = 0.980819817163073\n============================================\n\n","output_type":"stream"}],"execution_count":7}]}